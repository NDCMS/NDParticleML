{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd6a26cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook walks through the MonomialLayer class of polynomial.py.\\nUpdated 3/9/2023\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook walks through the MonomialLayer class of polynomial.py.\n",
    "Updated 3/9/2023\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eba4e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "273831cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current definition of MonomialLayer\n",
    "class MonomialLayer(nn.Module):\n",
    "    \"\"\"Outputs all possible monomials up to given degree from inpupts.\n",
    "\n",
    "    The basic idea is to add the number 1 to the list of inputs and\n",
    "    then create every possible monomial of the given degree from\n",
    "    factors of the inputs and one.  The presence of one in the list\n",
    "    generates the monomials with degree less than the given degree.\n",
    "    See the math of multisets for more information.  (Wikipedia has a\n",
    "    good entry on this.\n",
    "\n",
    "    Attributes:\n",
    "       n_inputs: The number of inputs this layer expects\n",
    "       degree: The maximum degree of the momomial\n",
    "       n_outputs: The number of monomials output\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs: int, degree: int) -> None:\n",
    "        \"\"\"Constructor\n",
    "\n",
    "        Args:\n",
    "            n_inputs: The number of input variables to the layer\n",
    "            degree: The maximum degree of the monomials\n",
    "        \"\"\"\n",
    "        \n",
    "        super(MonomialLayer,self).__init__()\n",
    "\n",
    "        self.n_inputs = n_inputs\n",
    "        self.degree = degree\n",
    "        # No point in keeping the constant term\n",
    "        self.n_outputs = int(math.factorial(n_inputs+degree) /\n",
    "                          math.factorial(n_inputs) /\n",
    "                          math.factorial(degree)) - 1\n",
    "\n",
    "        # Now, let's build an array of the indices of the inputs that\n",
    "        # need to be combined for each monomial\n",
    "        self.m_ind = torch.zeros(self.n_outputs,degree,dtype=torch.int32).cuda()\n",
    "        curr_ind = torch.zeros(self.degree, dtype=torch.int32).cuda()\n",
    "\n",
    "        for row in range(self.n_outputs):\n",
    "            # Calculate the values for this row\n",
    "            for col in range(self.degree-1,0,-1):\n",
    "                if curr_ind[col-1] > curr_ind[col]:\n",
    "                    curr_ind[col]+=1\n",
    "                    break\n",
    "                else:\n",
    "                    curr_ind[col]=0\n",
    "            else:\n",
    "                curr_ind[0]+=1\n",
    "                curr_ind[1:]=0 # Broadcasts!\n",
    "\n",
    "            # Set the indices for this row\n",
    "            self.m_ind[row,:] =  curr_ind\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Performs forward propagation for this module\n",
    "\n",
    "        Args: \n",
    "            x: \n",
    "              The input tensor to this layer.  This function preserves\n",
    "              all indices except the last one, which is assumed to\n",
    "              index the input variables.  Leading indices can be used\n",
    "              for minibatches or structuring the inputs.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if x.shape[-1] != self.n_inputs:\n",
    "            raise IndexError(f'Expecting {self.n_inputs} inputs, got {x.shape[-1]}')\n",
    "        x = torch.cat((torch.ones(x.shape[:-1]+(1,)).cuda(),x),axis=-1)\n",
    "        return torch.prod(torch.index_select(x,-1,self.m_ind.flatten())\n",
    "                          .reshape(x.shape[:-1]+self.m_ind.shape),axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81f9509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   2.,   2.,   4.,   3.,   3.,   6.,   9.,   4.,   4.,   8.,\n",
       "          12.,  16.,   5.,   5.,  10.,  15.,  20.,  25.,   6.,   6.,  12.,  18.,\n",
       "          24.,  30.,  36.,   7.,   7.,  14.,  21.,  28.,  35.,  42.,  49.,   8.,\n",
       "           8.,  16.,  24.,  32.,  40.,  48.,  56.,  64.,   9.,   9.,  18.,  27.,\n",
       "          36.,  45.,  54.,  63.,  72.,  81.,  10.,  10.,  20.,  30.,  40.,  50.,\n",
       "          60.,  70.,  80.,  90., 100.,  11.,  11.,  22.,  33.,  44.,  55.,  66.,\n",
       "          77.,  88.,  99., 110., 121.,  12.,  12.,  24.,  36.,  48.,  60.,  72.,\n",
       "          84.,  96., 108., 120., 132., 144.,  13.,  13.,  26.,  39.,  52.,  65.,\n",
       "          78.,  91., 104., 117., 130., 143., 156., 169.,  14.,  14.,  28.,  42.,\n",
       "          56.,  70.,  84.,  98., 112., 126., 140., 154., 168., 182., 196.,  15.,\n",
       "          15.,  30.,  45.,  60.,  75.,  90., 105., 120., 135., 150., 165., 180.,\n",
       "         195., 210., 225.,  16.,  16.,  32.,  48.,  64.,  80.,  96., 112., 128.,\n",
       "         144., 160., 176., 192., 208., 224., 240., 256.]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick demonstration\n",
    "mono = MonomialLayer(16, 2)\n",
    "x = torch.tensor([[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]]).cuda()\n",
    "mono.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "517352b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through little by little\n",
    "n_inputs = 16\n",
    "degree = 2\n",
    "# No point in keeping the constant term\n",
    "n_outputs = int(math.factorial(n_inputs+degree) /\n",
    "                          math.factorial(n_inputs) /\n",
    "                          math.factorial(degree)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27168543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([0, 0], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Now, let's build an array of the indices of the inputs that\n",
    "        # need to be combined for each monomial\n",
    "m_ind = torch.zeros(n_outputs,degree,dtype=torch.int32).cuda()\n",
    "curr_ind = torch.zeros(degree, dtype=torch.int32).cuda()\n",
    "print (m_ind)\n",
    "print (curr_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "239717ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(n_outputs):\n",
    "    # Calculate the values for this row\n",
    "    for col in range(degree-1,0,-1):\n",
    "        if curr_ind[col-1] > curr_ind[col]:\n",
    "            curr_ind[col]+=1\n",
    "            break\n",
    "        else:\n",
    "            curr_ind[col]=0\n",
    "    else:\n",
    "        curr_ind[0]+=1\n",
    "        curr_ind[1:]=0 # Broadcasts!\n",
    "\n",
    "    # Set the indices for this row\n",
    "    m_ind[row,:] =  curr_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68b3f98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0],\n",
       "        [ 1,  1],\n",
       "        [ 2,  0],\n",
       "        [ 2,  1],\n",
       "        [ 2,  2],\n",
       "        [ 3,  0],\n",
       "        [ 3,  1],\n",
       "        [ 3,  2],\n",
       "        [ 3,  3],\n",
       "        [ 4,  0],\n",
       "        [ 4,  1],\n",
       "        [ 4,  2],\n",
       "        [ 4,  3],\n",
       "        [ 4,  4],\n",
       "        [ 5,  0],\n",
       "        [ 5,  1],\n",
       "        [ 5,  2],\n",
       "        [ 5,  3],\n",
       "        [ 5,  4],\n",
       "        [ 5,  5],\n",
       "        [ 6,  0],\n",
       "        [ 6,  1],\n",
       "        [ 6,  2],\n",
       "        [ 6,  3],\n",
       "        [ 6,  4],\n",
       "        [ 6,  5],\n",
       "        [ 6,  6],\n",
       "        [ 7,  0],\n",
       "        [ 7,  1],\n",
       "        [ 7,  2],\n",
       "        [ 7,  3],\n",
       "        [ 7,  4],\n",
       "        [ 7,  5],\n",
       "        [ 7,  6],\n",
       "        [ 7,  7],\n",
       "        [ 8,  0],\n",
       "        [ 8,  1],\n",
       "        [ 8,  2],\n",
       "        [ 8,  3],\n",
       "        [ 8,  4],\n",
       "        [ 8,  5],\n",
       "        [ 8,  6],\n",
       "        [ 8,  7],\n",
       "        [ 8,  8],\n",
       "        [ 9,  0],\n",
       "        [ 9,  1],\n",
       "        [ 9,  2],\n",
       "        [ 9,  3],\n",
       "        [ 9,  4],\n",
       "        [ 9,  5],\n",
       "        [ 9,  6],\n",
       "        [ 9,  7],\n",
       "        [ 9,  8],\n",
       "        [ 9,  9],\n",
       "        [10,  0],\n",
       "        [10,  1],\n",
       "        [10,  2],\n",
       "        [10,  3],\n",
       "        [10,  4],\n",
       "        [10,  5],\n",
       "        [10,  6],\n",
       "        [10,  7],\n",
       "        [10,  8],\n",
       "        [10,  9],\n",
       "        [10, 10],\n",
       "        [11,  0],\n",
       "        [11,  1],\n",
       "        [11,  2],\n",
       "        [11,  3],\n",
       "        [11,  4],\n",
       "        [11,  5],\n",
       "        [11,  6],\n",
       "        [11,  7],\n",
       "        [11,  8],\n",
       "        [11,  9],\n",
       "        [11, 10],\n",
       "        [11, 11],\n",
       "        [12,  0],\n",
       "        [12,  1],\n",
       "        [12,  2],\n",
       "        [12,  3],\n",
       "        [12,  4],\n",
       "        [12,  5],\n",
       "        [12,  6],\n",
       "        [12,  7],\n",
       "        [12,  8],\n",
       "        [12,  9],\n",
       "        [12, 10],\n",
       "        [12, 11],\n",
       "        [12, 12],\n",
       "        [13,  0],\n",
       "        [13,  1],\n",
       "        [13,  2],\n",
       "        [13,  3],\n",
       "        [13,  4],\n",
       "        [13,  5],\n",
       "        [13,  6],\n",
       "        [13,  7],\n",
       "        [13,  8],\n",
       "        [13,  9],\n",
       "        [13, 10],\n",
       "        [13, 11],\n",
       "        [13, 12],\n",
       "        [13, 13],\n",
       "        [14,  0],\n",
       "        [14,  1],\n",
       "        [14,  2],\n",
       "        [14,  3],\n",
       "        [14,  4],\n",
       "        [14,  5],\n",
       "        [14,  6],\n",
       "        [14,  7],\n",
       "        [14,  8],\n",
       "        [14,  9],\n",
       "        [14, 10],\n",
       "        [14, 11],\n",
       "        [14, 12],\n",
       "        [14, 13],\n",
       "        [14, 14],\n",
       "        [15,  0],\n",
       "        [15,  1],\n",
       "        [15,  2],\n",
       "        [15,  3],\n",
       "        [15,  4],\n",
       "        [15,  5],\n",
       "        [15,  6],\n",
       "        [15,  7],\n",
       "        [15,  8],\n",
       "        [15,  9],\n",
       "        [15, 10],\n",
       "        [15, 11],\n",
       "        [15, 12],\n",
       "        [15, 13],\n",
       "        [15, 14],\n",
       "        [15, 15],\n",
       "        [16,  0],\n",
       "        [16,  1],\n",
       "        [16,  2],\n",
       "        [16,  3],\n",
       "        [16,  4],\n",
       "        [16,  5],\n",
       "        [16,  6],\n",
       "        [16,  7],\n",
       "        [16,  8],\n",
       "        [16,  9],\n",
       "        [16, 10],\n",
       "        [16, 11],\n",
       "        [16, 12],\n",
       "        [16, 13],\n",
       "        [16, 14],\n",
       "        [16, 15],\n",
       "        [16, 16]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a1fb887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50c6edd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[:-1]+(1,) # concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "876c2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat((torch.ones(x.shape[:-1]+(1,)).cuda(),x),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccdcdf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "         14., 15., 16.]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1bd2ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0,  1,  1,  2,  0,  2,  1,  2,  2,  3,  0,  3,  1,  3,  2,  3,  3,\n",
       "         4,  0,  4,  1,  4,  2,  4,  3,  4,  4,  5,  0,  5,  1,  5,  2,  5,  3,\n",
       "         5,  4,  5,  5,  6,  0,  6,  1,  6,  2,  6,  3,  6,  4,  6,  5,  6,  6,\n",
       "         7,  0,  7,  1,  7,  2,  7,  3,  7,  4,  7,  5,  7,  6,  7,  7,  8,  0,\n",
       "         8,  1,  8,  2,  8,  3,  8,  4,  8,  5,  8,  6,  8,  7,  8,  8,  9,  0,\n",
       "         9,  1,  9,  2,  9,  3,  9,  4,  9,  5,  9,  6,  9,  7,  9,  8,  9,  9,\n",
       "        10,  0, 10,  1, 10,  2, 10,  3, 10,  4, 10,  5, 10,  6, 10,  7, 10,  8,\n",
       "        10,  9, 10, 10, 11,  0, 11,  1, 11,  2, 11,  3, 11,  4, 11,  5, 11,  6,\n",
       "        11,  7, 11,  8, 11,  9, 11, 10, 11, 11, 12,  0, 12,  1, 12,  2, 12,  3,\n",
       "        12,  4, 12,  5, 12,  6, 12,  7, 12,  8, 12,  9, 12, 10, 12, 11, 12, 12,\n",
       "        13,  0, 13,  1, 13,  2, 13,  3, 13,  4, 13,  5, 13,  6, 13,  7, 13,  8,\n",
       "        13,  9, 13, 10, 13, 11, 13, 12, 13, 13, 14,  0, 14,  1, 14,  2, 14,  3,\n",
       "        14,  4, 14,  5, 14,  6, 14,  7, 14,  8, 14,  9, 14, 10, 14, 11, 14, 12,\n",
       "        14, 13, 14, 14, 15,  0, 15,  1, 15,  2, 15,  3, 15,  4, 15,  5, 15,  6,\n",
       "        15,  7, 15,  8, 15,  9, 15, 10, 15, 11, 15, 12, 15, 13, 15, 14, 15, 15,\n",
       "        16,  0, 16,  1, 16,  2, 16,  3, 16,  4, 16,  5, 16,  6, 16,  7, 16,  8,\n",
       "        16,  9, 16, 10, 16, 11, 16, 12, 16, 13, 16, 14, 16, 15, 16, 16],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ind.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e96b9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  1.,  2.,  1.,  2.,  1.,  2.,  2.,  3.,  1.,  3.,  1.,\n",
       "          3.,  2.,  3.,  3.,  4.,  1.,  4.,  1.,  4.,  2.,  4.,  3.,  4.,  4.,\n",
       "          5.,  1.,  5.,  1.,  5.,  2.,  5.,  3.,  5.,  4.,  5.,  5.,  6.,  1.,\n",
       "          6.,  1.,  6.,  2.,  6.,  3.,  6.,  4.,  6.,  5.,  6.,  6.,  7.,  1.,\n",
       "          7.,  1.,  7.,  2.,  7.,  3.,  7.,  4.,  7.,  5.,  7.,  6.,  7.,  7.,\n",
       "          8.,  1.,  8.,  1.,  8.,  2.,  8.,  3.,  8.,  4.,  8.,  5.,  8.,  6.,\n",
       "          8.,  7.,  8.,  8.,  9.,  1.,  9.,  1.,  9.,  2.,  9.,  3.,  9.,  4.,\n",
       "          9.,  5.,  9.,  6.,  9.,  7.,  9.,  8.,  9.,  9., 10.,  1., 10.,  1.,\n",
       "         10.,  2., 10.,  3., 10.,  4., 10.,  5., 10.,  6., 10.,  7., 10.,  8.,\n",
       "         10.,  9., 10., 10., 11.,  1., 11.,  1., 11.,  2., 11.,  3., 11.,  4.,\n",
       "         11.,  5., 11.,  6., 11.,  7., 11.,  8., 11.,  9., 11., 10., 11., 11.,\n",
       "         12.,  1., 12.,  1., 12.,  2., 12.,  3., 12.,  4., 12.,  5., 12.,  6.,\n",
       "         12.,  7., 12.,  8., 12.,  9., 12., 10., 12., 11., 12., 12., 13.,  1.,\n",
       "         13.,  1., 13.,  2., 13.,  3., 13.,  4., 13.,  5., 13.,  6., 13.,  7.,\n",
       "         13.,  8., 13.,  9., 13., 10., 13., 11., 13., 12., 13., 13., 14.,  1.,\n",
       "         14.,  1., 14.,  2., 14.,  3., 14.,  4., 14.,  5., 14.,  6., 14.,  7.,\n",
       "         14.,  8., 14.,  9., 14., 10., 14., 11., 14., 12., 14., 13., 14., 14.,\n",
       "         15.,  1., 15.,  1., 15.,  2., 15.,  3., 15.,  4., 15.,  5., 15.,  6.,\n",
       "         15.,  7., 15.,  8., 15.,  9., 15., 10., 15., 11., 15., 12., 15., 13.,\n",
       "         15., 14., 15., 15., 16.,  1., 16.,  1., 16.,  2., 16.,  3., 16.,  4.,\n",
       "         16.,  5., 16.,  6., 16.,  7., 16.,  8., 16.,  9., 16., 10., 16., 11.,\n",
       "         16., 12., 16., 13., 16., 14., 16., 15., 16., 16.]], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(x,-1,m_ind.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9de70224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 152, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[:-1]+m_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf6d898d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.],\n",
       "         [ 1.,  1.],\n",
       "         [ 2.,  1.],\n",
       "         [ 2.,  1.],\n",
       "         [ 2.,  2.],\n",
       "         [ 3.,  1.],\n",
       "         [ 3.,  1.],\n",
       "         [ 3.,  2.],\n",
       "         [ 3.,  3.],\n",
       "         [ 4.,  1.],\n",
       "         [ 4.,  1.],\n",
       "         [ 4.,  2.],\n",
       "         [ 4.,  3.],\n",
       "         [ 4.,  4.],\n",
       "         [ 5.,  1.],\n",
       "         [ 5.,  1.],\n",
       "         [ 5.,  2.],\n",
       "         [ 5.,  3.],\n",
       "         [ 5.,  4.],\n",
       "         [ 5.,  5.],\n",
       "         [ 6.,  1.],\n",
       "         [ 6.,  1.],\n",
       "         [ 6.,  2.],\n",
       "         [ 6.,  3.],\n",
       "         [ 6.,  4.],\n",
       "         [ 6.,  5.],\n",
       "         [ 6.,  6.],\n",
       "         [ 7.,  1.],\n",
       "         [ 7.,  1.],\n",
       "         [ 7.,  2.],\n",
       "         [ 7.,  3.],\n",
       "         [ 7.,  4.],\n",
       "         [ 7.,  5.],\n",
       "         [ 7.,  6.],\n",
       "         [ 7.,  7.],\n",
       "         [ 8.,  1.],\n",
       "         [ 8.,  1.],\n",
       "         [ 8.,  2.],\n",
       "         [ 8.,  3.],\n",
       "         [ 8.,  4.],\n",
       "         [ 8.,  5.],\n",
       "         [ 8.,  6.],\n",
       "         [ 8.,  7.],\n",
       "         [ 8.,  8.],\n",
       "         [ 9.,  1.],\n",
       "         [ 9.,  1.],\n",
       "         [ 9.,  2.],\n",
       "         [ 9.,  3.],\n",
       "         [ 9.,  4.],\n",
       "         [ 9.,  5.],\n",
       "         [ 9.,  6.],\n",
       "         [ 9.,  7.],\n",
       "         [ 9.,  8.],\n",
       "         [ 9.,  9.],\n",
       "         [10.,  1.],\n",
       "         [10.,  1.],\n",
       "         [10.,  2.],\n",
       "         [10.,  3.],\n",
       "         [10.,  4.],\n",
       "         [10.,  5.],\n",
       "         [10.,  6.],\n",
       "         [10.,  7.],\n",
       "         [10.,  8.],\n",
       "         [10.,  9.],\n",
       "         [10., 10.],\n",
       "         [11.,  1.],\n",
       "         [11.,  1.],\n",
       "         [11.,  2.],\n",
       "         [11.,  3.],\n",
       "         [11.,  4.],\n",
       "         [11.,  5.],\n",
       "         [11.,  6.],\n",
       "         [11.,  7.],\n",
       "         [11.,  8.],\n",
       "         [11.,  9.],\n",
       "         [11., 10.],\n",
       "         [11., 11.],\n",
       "         [12.,  1.],\n",
       "         [12.,  1.],\n",
       "         [12.,  2.],\n",
       "         [12.,  3.],\n",
       "         [12.,  4.],\n",
       "         [12.,  5.],\n",
       "         [12.,  6.],\n",
       "         [12.,  7.],\n",
       "         [12.,  8.],\n",
       "         [12.,  9.],\n",
       "         [12., 10.],\n",
       "         [12., 11.],\n",
       "         [12., 12.],\n",
       "         [13.,  1.],\n",
       "         [13.,  1.],\n",
       "         [13.,  2.],\n",
       "         [13.,  3.],\n",
       "         [13.,  4.],\n",
       "         [13.,  5.],\n",
       "         [13.,  6.],\n",
       "         [13.,  7.],\n",
       "         [13.,  8.],\n",
       "         [13.,  9.],\n",
       "         [13., 10.],\n",
       "         [13., 11.],\n",
       "         [13., 12.],\n",
       "         [13., 13.],\n",
       "         [14.,  1.],\n",
       "         [14.,  1.],\n",
       "         [14.,  2.],\n",
       "         [14.,  3.],\n",
       "         [14.,  4.],\n",
       "         [14.,  5.],\n",
       "         [14.,  6.],\n",
       "         [14.,  7.],\n",
       "         [14.,  8.],\n",
       "         [14.,  9.],\n",
       "         [14., 10.],\n",
       "         [14., 11.],\n",
       "         [14., 12.],\n",
       "         [14., 13.],\n",
       "         [14., 14.],\n",
       "         [15.,  1.],\n",
       "         [15.,  1.],\n",
       "         [15.,  2.],\n",
       "         [15.,  3.],\n",
       "         [15.,  4.],\n",
       "         [15.,  5.],\n",
       "         [15.,  6.],\n",
       "         [15.,  7.],\n",
       "         [15.,  8.],\n",
       "         [15.,  9.],\n",
       "         [15., 10.],\n",
       "         [15., 11.],\n",
       "         [15., 12.],\n",
       "         [15., 13.],\n",
       "         [15., 14.],\n",
       "         [15., 15.],\n",
       "         [16.,  1.],\n",
       "         [16.,  1.],\n",
       "         [16.,  2.],\n",
       "         [16.,  3.],\n",
       "         [16.,  4.],\n",
       "         [16.,  5.],\n",
       "         [16.,  6.],\n",
       "         [16.,  7.],\n",
       "         [16.,  8.],\n",
       "         [16.,  9.],\n",
       "         [16., 10.],\n",
       "         [16., 11.],\n",
       "         [16., 12.],\n",
       "         [16., 13.],\n",
       "         [16., 14.],\n",
       "         [16., 15.],\n",
       "         [16., 16.]]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(x,-1,m_ind.flatten()).reshape(x.shape[:-1]+m_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "115dfc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   2.,   2.,   4.,   3.,   3.,   6.,   9.,   4.,   4.,   8.,\n",
       "          12.,  16.,   5.,   5.,  10.,  15.,  20.,  25.,   6.,   6.,  12.,  18.,\n",
       "          24.,  30.,  36.,   7.,   7.,  14.,  21.,  28.,  35.,  42.,  49.,   8.,\n",
       "           8.,  16.,  24.,  32.,  40.,  48.,  56.,  64.,   9.,   9.,  18.,  27.,\n",
       "          36.,  45.,  54.,  63.,  72.,  81.,  10.,  10.,  20.,  30.,  40.,  50.,\n",
       "          60.,  70.,  80.,  90., 100.,  11.,  11.,  22.,  33.,  44.,  55.,  66.,\n",
       "          77.,  88.,  99., 110., 121.,  12.,  12.,  24.,  36.,  48.,  60.,  72.,\n",
       "          84.,  96., 108., 120., 132., 144.,  13.,  13.,  26.,  39.,  52.,  65.,\n",
       "          78.,  91., 104., 117., 130., 143., 156., 169.,  14.,  14.,  28.,  42.,\n",
       "          56.,  70.,  84.,  98., 112., 126., 140., 154., 168., 182., 196.,  15.,\n",
       "          15.,  30.,  45.,  60.,  75.,  90., 105., 120., 135., 150., 165., 180.,\n",
       "         195., 210., 225.,  16.,  16.,  32.,  48.,  64.,  80.,  96., 112., 128.,\n",
       "         144., 160., 176., 192., 208., 224., 240., 256.]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.prod(torch.index_select(x,-1,m_ind.flatten()).reshape(x.shape[:-1]+m_ind.shape),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab170477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
